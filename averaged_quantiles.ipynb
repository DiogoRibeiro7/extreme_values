{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "from pystan import StanModel \n",
    "from numpy import polyval, place, extract, any, asarray, nan, inf, pi\n",
    "from numpy import (where, arange, putmask, ravel, sum, shape,\n",
    "                   log, sqrt, exp, arctanh, tan, sin, arcsin, arctan,\n",
    "                   tanh, cos, cosh, sinh, log1p, expm1)\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import f\n",
    "\n",
    "\n",
    "class frechet_gen(rv_continuous):\n",
    "#     def _argcheck(self, c):\n",
    "#         c = asarray(c)\n",
    "#         self.b = where(c < 0, 1.0/abs(c), inf)\n",
    "#         return where(c == 0, 0, 1)\n",
    "\n",
    "#     def _pdf(self, x, alpha1, alpha2, beta):\n",
    "#         Px = 1 / beta / ss.beta(alpha1, alpha2) * pow(x/beta, asarray(alpha1-1.0)) * pow(1 + x/beta, asarray(- alpha1 - alpha2))\n",
    "#         return Px\n",
    "\n",
    "#     def _logpdf(self, x, alpha1, alpha2, beta):\n",
    "#         return (alpha1 - 1) * np.log(x) - alpha1 * np.log(beta) - np.log(ss.beta(alpha1, alpha2)) - (alpha1 + alpha2) * np.log(1 + x/beta)\n",
    "\n",
    "    def _cdf(self, x, beta):\n",
    "        return exp(-pow(x, -1/beta))\n",
    "#     def _ppf(self, q, c):\n",
    "#         vals = 1.0/c * (pow(1-q, -c)-1)\n",
    "#         return vals\n",
    "\n",
    "#     def _munp(self, n, c):\n",
    "#         k = arange(0, n+1)\n",
    "#         val = (-1.0/c)**n * sum(comb(n, k)*(-1)**k / (1.0-c*k), axis=0)\n",
    "#         return where(c*n < 1, val, inf)\n",
    "\n",
    "#     def _entropy(self, c):\n",
    "#         if (c > 0):\n",
    "#             return 1+c\n",
    "#         else:\n",
    "#             self.b = -1.0 / c\n",
    "#             return rv_continuous._entropy(self, c)\n",
    "frechet = frechet_gen(a=0.0, name='frechet') # we specify the support [a,b], no b means b = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a function to get a excesses\n",
    "def k_greatest_values(a,k):\n",
    "    \"\"\"returns k greatest elements from the list and k-1 value starting from which we consider values to be extreme\"\"\"\n",
    "    u = np.sort(a, axis=None)[-1-k]\n",
    "    a = np.sort(a, axis=None)[-1-k+1:]\n",
    "    a = asarray([a-u for x in a])\n",
    "    return(a[1].tolist(), u) # u the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y, real alpha, real beta) {\n",
    "      return -(alpha + 1)*( log(1+y/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  \n",
    "  real myBetaPrior(real x, real beta) {\n",
    "      return -log(beta); // log(1/beta) = log(1) - log(beta) = - log(beta)\n",
    "  }\n",
    "  \n",
    "  \n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors; no priors - we assume improper priors on params\n",
    "  alpha ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher = \"\"\"\n",
    "functions { \n",
    " real myFisher_lpdf(real y, real alpha1, real alpha2, real beta) {\n",
    "      return -lbeta(alpha1,alpha2)-log(beta)+(alpha1-1)*log(y/beta)-(alpha1+alpha2)*log(1+y/beta);\n",
    "  }\n",
    "  \n",
    "// to recover more general distribution of Fisher parametrized by three parameters we need to multiply the above distribution \n",
    "// by: df1**df1/2\n",
    "// we have alpha1,2 = df1,2/2, beta = df2/df1\n",
    "}\n",
    "\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from fisher in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  //parameters of the Fisher\n",
    "  //real df1;\n",
    "  //real df2;\n",
    "  real<lower=0> alpha1;\n",
    "  real<lower=0> alpha2;\n",
    "  real<lower=0> beta;\n",
    "  \n",
    "}\n",
    "model {\n",
    "  // when we deliberately do not specify priors then Stan works with improper priors\n",
    "  alpha1 ~ gamma(1,1);\n",
    "  alpha2 ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "   // Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myFisher_lpdf( y[n] |alpha1, alpha2, beta);\n",
    "  }\n",
    "}\n",
    "\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantiles_GPD(excesses, k, u): \n",
    "    \"\"\" \n",
    "    we forward to function array of the quantiles as excesses, the number of excesses, k, and the border value u\n",
    "    \"\"\"\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_GPD = np.zeros(len(q)) \n",
    "    bayesian_quant_GPD = np.zeros(len(q))\n",
    "    \n",
    "#     k = 100 # number of excesses\n",
    "#     frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = excesses) \n",
    "    fit = StanModel(model_code=GPD).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate GPD quantiles and their traceplots to calculate Bayesian GPD quantiles\n",
    "    traceplot_beta_GPD = list(fit.extract().values())[1].tolist() \n",
    "    traceplot_alpha = list(fit.extract().values())[0].tolist()\n",
    "    traceplot_gamma = np.divide(np.ones(len(traceplot_alpha)), traceplot_alpha)\n",
    "    beta_GPD = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    gamma = 1 / alpha \n",
    "    \n",
    "    # we also want to keep track of parameters from each fit\n",
    "#     values_of_beta_GPD = np.zeros(n)\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_GPD[i] = u + beta_GPD*( pow( N * (1-q[i]) / k, -gamma ) - 1 ) \n",
    "        for j in range(len(traceplot_gamma)):\n",
    "                bayesian_quant_GPD[i] = bayesian_quant_GPD[i] + u + traceplot_beta_GPD[j] * (pow( N * (1 - q[i]) / k, - traceplot_gamma[j] ) - 1)\n",
    "    bayesian_quant_GPD = bayesian_quant_GPD / len(traceplot_gamma)\n",
    "    list_of_params = [alpha, beta_GPD]\n",
    "    return(quant_GPD, bayesian_quant_GPD, list_of_params ) # it return arrays: quant_GPD, bayesian_quant_GPD and values alpha, beta_GPD\n",
    "\n",
    "# now the same as above but for Fisher quantiles\n",
    "def quantiles_Fisher(excesses, k, u):\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_Fisher = np.zeros(len(q)) \n",
    "    bayesian_quant_Fisher = np.zeros(len(q))\n",
    "    \n",
    "#     k = 100 # number of excesses\n",
    "#     frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = excesses) \n",
    "    fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate Fisher quantiles and their traceplots to calculate Bayesian Fisher quantiles\n",
    "    traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "    traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "    traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "    beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "    alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    beta0 = alpha2/alpha1\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_Fisher[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "        for j in range(len(traceplot_alpha1)):\n",
    "                bayesian_quant_Fisher[i] = bayesian_quant_Fisher[i] + u + traceplot_alpha2[j] / traceplot_alpha1[j] / traceplot_beta[j] * f.isf(N / k *(1- q[i]), 2 * traceplot_alpha1[j], 2 * traceplot_alpha2[j], loc=0, scale=1)\n",
    "    bayesian_quant_Fisher = bayesian_quant_Fisher / len(traceplot_alpha1)\n",
    "    list_of_params = [alpha1, alpha2, beta]\n",
    "    return(quant_Fisher, bayesian_quant_Fisher, list_of_params) # it return arrays: quant_Fisher, bayesian_quant_Fisher and values of params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_greatest_values_matrices(a,k):\n",
    "    \"\"\"returns k greatest elements from the list a and k - 1 value starting from which we consider greater values as extremes\"\"\"\n",
    "    # we prepare the matrix for the excesses, the last value of 1 could be substituted by any value within the range\n",
    "    mat = np.zeros( len(a[-1 - k + 1 : , 1] ) ) \n",
    "    # we prepare the vector in which we will return u values for each dataset in column of a\n",
    "    u = np.zeros(len(r[0 , : ] )) \n",
    "    for i in range(len(a[0,:])): \n",
    "        # index i goes through the columns, instead of len(a[0,:]) there could be len(a[i,:]) for i in range of columns\n",
    "        u[i] = a[-1 - k, i] \n",
    "        # u is a list of values s.t. bigger values are considered as excesses, for each set of data, i.e. for each column we save an u value\n",
    "        mat = np.column_stack( (mat,a[ -1 - k + 1 : , i]) ) \n",
    "    # in mat matrix we return the values of excesses but not yet transformed (y_i = x_i - u)\n",
    "    return(mat, u) # u is the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 # number of sampled dataset over which we average the quantiles\n",
    "N, beta, k = 1000,  1/2, 100\n",
    "q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "\n",
    "r = frechet.rvs(beta, size=N)\n",
    "for i in range(n):\n",
    "    r = np.column_stack( (r, frechet.rvs(beta, size=N) ) ) \n",
    "\n",
    "# we need to sort in increasing order gathered data\n",
    "for i in range(len(r[0,:])):\n",
    "    r[:,i] = np.sort(r[:,i], axis=None)# we sort data sampled from frechet, each dataset is in separate column\n",
    "    \n",
    "# in data frechet we keep the matrix of excesses, each sampled data set is in \n",
    "data_frechet,u = k_greatest_values_matrices(r,k) \n",
    "\n",
    "# delete first column of a matrix A, to match the sizes \n",
    "A = np.delete(data_frechet, 0, 1)\n",
    "# form the array of u values we create matrix, in columns we have repeated u values   \n",
    "B = [ [x] * k for x in u ] \n",
    "\n",
    "# here we subtract u_i from excesses in each dataset\n",
    "C = np.array(A) - np.array(B).transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1561b2fac3108872ed6bafb6d2492041 NOW.\n",
      "C:\\Users\\Michal Lewandowski\\Anaconda3\\envs\\py35\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_04eca6d0a20a624d371a8c595ed628be NOW.\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1561b2fac3108872ed6bafb6d2492041 NOW.\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_04eca6d0a20a624d371a8c595ed628be NOW.\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1561b2fac3108872ed6bafb6d2492041 NOW.\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_04eca6d0a20a624d371a8c595ed628be NOW.\n"
     ]
    }
   ],
   "source": [
    "averaged_quant_GPD, averaged_bayesian_quant_GPD, averaged_params_GPD = np.zeros(len(q)), np.zeros(len(q)), np.zeros(2)\n",
    "averaged_quant_Fisher, averaged_bayesian_quant_Fisher, averaged_params_Fisher = np.zeros(len(q)), np.zeros(len(q)), np.zeros(3)\n",
    "\n",
    "# to compute standard deviation of the quantiles we need to store the values of quantiles after each iteration and use np.sd(array)\n",
    "# sd_averaged_quant_GPD_q90 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_GPD_q90 = np.zeros(n)\n",
    "# sd_averaged_quant_Fisher_q90 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_Fisher_q90 = np.zeros(n)\n",
    "# sd_averaged_params_Fisher_q90 = np.zeros(n)\n",
    "\n",
    "# sd_averaged_quant_GPD_q95 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_GPD_q95 = np.zeros(n)\n",
    "# sd_averaged_quant_Fisher_q95 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_Fisher_q95 = np.zeros(n)\n",
    "# sd_averaged_params_Fisher_q95 = np.zeros(n)\n",
    "\n",
    "# sd_averaged_quant_GPD_q975 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_GPD_q975 = np.zeros(n)\n",
    "# sd_averaged_quant_Fisher_q975 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_Fisher_q975 = np.zeros(n)\n",
    "# sd_averaged_params_Fisher_q975 = np.zeros(n)\n",
    "\n",
    "# sd_averaged_quant_GPD_q99 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_GPD_q99 = np.zeros(n)\n",
    "# sd_averaged_quant_Fisher_q99 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_Fisher_q99 = np.zeros(n)\n",
    "# sd_averaged_params_Fisher_q99 = np.zeros(n)\n",
    "\n",
    "# sd_averaged_quant_GPD_q999 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_GPD_q999 = np.zeros(n)\n",
    "# sd_averaged_quant_Fisher_q999 = np.zeros(n)\n",
    "# sd_averaged_bayesian_quant_Fisher_q999 = np.zeros(n)\n",
    "# sd_averaged_params_Fisher_q999 = np.zeros(n)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(n):   \n",
    "    excesses_array = asarray(C.transpose().tolist()[i])\n",
    "    quant_GPD, bayesian_quant_GPD, params_GPD = quantiles_GPD(excesses_array, k, u[i])\n",
    "    quant_Fisher, bayesian_quant_Fisher, params_Fisher = quantiles_Fisher(excesses_array, k, u[i])\n",
    "    \n",
    "#     sd_averaged_quant_GPD_q90[i] = quant_GPD[0]\n",
    "#     sd_averaged_bayesian_quant_GPD_q90[i] = bayesian_quant_GPD[1]\n",
    "#     sd_averaged_quant_Fisher_q90[i] = quant_Fisher[2]\n",
    "#     sd_averaged_bayesian_quant_Fisher_q90[i] = bayesian_quant_Fisher[3]\n",
    "    \n",
    "#     sd_averaged_quant_GPD_q95 = np.zeros(n)\n",
    "#     sd_averaged_bayesian_quant_GPD_q95 = np.zeros(n)\n",
    "#     sd_averaged_quant_Fisher_q95 = np.zeros(n)\n",
    "#     sd_averaged_bayesian_quant_Fisher_q95 = np.zeros(n)\n",
    "#     sd_averaged_params_Fisher_q95 = np.zeros(n)\n",
    "    \n",
    "    averaged_quant_GPD += quant_GPD\n",
    "    averaged_bayesian_quant_GPD += bayesian_quant_GPD\n",
    "    averaged_params_GPD += params_GPD \n",
    "\n",
    "    averaged_quant_Fisher += quant_Fisher\n",
    "    averaged_bayesian_quant_Fisher += bayesian_quant_Fisher\n",
    "    averaged_params_Fisher += params_Fisher \n",
    "\n",
    "averaged_quant_GPD = averaged_quant_GPD / ( n  ) # as we iterate from i = [ 0 to i = n ) we have n simulations in total\n",
    "averaged_bayesian_quant_GPD = averaged_bayesian_quant_GPD / ( n  )\n",
    "averaged_params_GPD = asarray(averaged_params_GPD) / ( n  )\n",
    "\n",
    "averaged_quant_Fisher = averaged_quant_Fisher / ( n  ) # as we iterate from i = 0 to i = n we have n simulations in total\n",
    "averaged_bayesian_quant_Fisher = averaged_bayesian_quant_Fisher / ( n  )\n",
    "averaged_params_Fisher = asarray(averaged_params_Fisher) / ( n  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_th = np.zeros(len(q))\n",
    "for i in range(len(q)):\n",
    "    quant_th[i] = pow(-log(q[i]), -beta)\n",
    "\n",
    "m = \"3\" # how much we round\n",
    "rounding = \"%.\" + m + \"f\"\n",
    "m = int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----+-------+-------+-------+-------+--------+\n",
      "|  how obtained | mean | sd | 92.5% |  95%  | 97.5% |  99%  | 99.9%  |\n",
      "+---------------+------+----+-------+-------+-------+-------+--------+\n",
      "| theoretically |  --  | -- | 3.081 | 4.415 | 6.285 | 9.975 | 31.615 |\n",
      "|  Bayes Fisher |  --  | -- | 3.122 | 3.776 | 4.788 | 7.354 | 39.160 |\n",
      "|     Fisher    |  --  | -- | 3.122 | 3.766 | 4.690 | 6.700 | 21.555 |\n",
      "|   Bayes GPD   |  --  | -- | 0.000 | 0.000 | 0.000 | 0.000 | 0.000  |\n",
      "|      GPD      |  --  | -- | 0.000 | 0.000 | 0.000 | 0.000 | 0.000  |\n",
      "+---------------+------+----+-------+-------+-------+-------+--------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "t_quantiles = PrettyTable(['how obtained',  'mean', 'sd', '92.5%', '95%', '97.5%', '99%', '99.9%'])\n",
    "# t_quantiles.add_row(['numpy', \n",
    "#            \"%.3f\" % round(np.mean(r),m),\n",
    "#            \"%.3f\" % round(np.std(r),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 92.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 95),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 97.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 99),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 99.9),m)])\n",
    "t_quantiles.add_row(['theoretically', '--', '--',\n",
    "                     rounding % round(quant_th[0],m),  \n",
    "                     rounding % round(quant_th[1], m), \n",
    "                     rounding % round(quant_th[2], m),\n",
    "                     rounding % round(quant_th[3], m),\n",
    "                     rounding % round(quant_th[4], m) ])\n",
    "t_quantiles.add_row(['Bayes Fisher',  '--', '--',\n",
    "                     rounding % round(averaged_bayesian_quant_Fisher[0],m),  \n",
    "                     rounding % round(averaged_bayesian_quant_Fisher[1], m), \n",
    "                     rounding % round(averaged_bayesian_quant_Fisher[2], m),\n",
    "                     rounding % round(averaged_bayesian_quant_Fisher[3], m),\n",
    "                     rounding % round(averaged_bayesian_quant_Fisher[4], m) ])\n",
    "t_quantiles.add_row(['Fisher',  '--', '--',\n",
    "                     rounding % round(averaged_quant_Fisher[0],m),  \n",
    "                     rounding % round(averaged_quant_Fisher[1], m), \n",
    "                     rounding % round(averaged_quant_Fisher[2], m),\n",
    "                     rounding % round(averaged_quant_Fisher[3], m),\n",
    "                     rounding % round(averaged_quant_Fisher[4], m) ])\n",
    "t_quantiles.add_row(['Bayes GPD', '--', '--',\n",
    "                     rounding % round(averaged_bayesian_quant_GPD[0],m),  \n",
    "                     rounding % round(averaged_bayesian_quant_GPD[1], m), \n",
    "                     rounding % round(averaged_bayesian_quant_GPD[2], m),\n",
    "                     rounding % round(averaged_bayesian_quant_GPD[3], m),\n",
    "                     rounding % round(averaged_bayesian_quant_GPD[4], m) ])\n",
    "t_quantiles.add_row(['GPD',  '--', '--',\n",
    "                     rounding % round(averaged_quant_GPD[0],m),  \n",
    "                     rounding % round(averaged_quant_GPD[1], m), \n",
    "                     rounding % round(averaged_quant_GPD[2], m),\n",
    "                     rounding % round(averaged_quant_GPD[3], m),\n",
    "                     rounding % round(averaged_quant_GPD[4], m) ])\n",
    "print(t_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " averaged_params_GPD:  [0. 0.] \n",
      " averaged_params_Fisher:  [1.17343837 1.62755757 2.08602232]\n"
     ]
    }
   ],
   "source": [
    "print(\" averaged_params_GPD: \", averaged_params_GPD, \"\\n\", \"averaged_params_Fisher: \", averaged_params_Fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variability plots for n = 10 replications but for 50 different values of k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jump_excesses = np.linspace(20, N/2, 50).astype(int) # astype function converts the values in the array to integers\n",
    "jump_excesses[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
