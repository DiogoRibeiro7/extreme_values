{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "from pystan import StanModel \n",
    "from numpy import polyval, place, extract, any, asarray, nan, inf, pi\n",
    "from numpy import (where, arange, putmask, ravel, sum, shape,\n",
    "                   log, sqrt, exp, arctanh, tan, sin, arcsin, arctan,\n",
    "                   tanh, cos, cosh, sinh, log1p, expm1)\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import f\n",
    "\n",
    "\n",
    "class frechet_gen(rv_continuous):\n",
    "#     def _argcheck(self, c):\n",
    "#         c = asarray(c)\n",
    "#         self.b = where(c < 0, 1.0/abs(c), inf)\n",
    "#         return where(c == 0, 0, 1)\n",
    "\n",
    "#     def _pdf(self, x, alpha1, alpha2, beta):\n",
    "#         Px = 1 / beta / ss.beta(alpha1, alpha2) * pow(x/beta, asarray(alpha1-1.0)) * pow(1 + x/beta, asarray(- alpha1 - alpha2))\n",
    "#         return Px\n",
    "\n",
    "#     def _logpdf(self, x, alpha1, alpha2, beta):\n",
    "#         return (alpha1 - 1) * np.log(x) - alpha1 * np.log(beta) - np.log(ss.beta(alpha1, alpha2)) - (alpha1 + alpha2) * np.log(1 + x/beta)\n",
    "\n",
    "    def _cdf(self, x, beta):\n",
    "        return exp(-pow(x, -1/beta))\n",
    "#     def _ppf(self, q, c):\n",
    "#         vals = 1.0/c * (pow(1-q, -c)-1)\n",
    "#         return vals\n",
    "\n",
    "#     def _munp(self, n, c):\n",
    "#         k = arange(0, n+1)\n",
    "#         val = (-1.0/c)**n * sum(comb(n, k)*(-1)**k / (1.0-c*k), axis=0)\n",
    "#         return where(c*n < 1, val, inf)\n",
    "\n",
    "#     def _entropy(self, c):\n",
    "#         if (c > 0):\n",
    "#             return 1+c\n",
    "#         else:\n",
    "#             self.b = -1.0 / c\n",
    "#             return rv_continuous._entropy(self, c)\n",
    "frechet = frechet_gen(a=0.0, name='frechet') # we specify the support [a,b], no b means b = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are able to sample rv exactly as in publication\n",
    "N, beta = 1000,  1/2 # run with n = 1000000\n",
    "# beta = 1/2 because we want to have a finite mean and for this beta we could check that the code is good\n",
    "r = frechet.rvs(beta, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of data\n",
    "fig, ax = plt.subplots(figsize=[8,6])\n",
    "\n",
    "# set plot title\n",
    "ax.set_title(\"Data sampled from Frechet \")\n",
    "\n",
    "# set x-axis name\n",
    "ax.set_xlabel(\"value\")\n",
    "\n",
    "# set y-axis name\n",
    "ax.set_ylabel(\"number of records\")\n",
    "\n",
    "# create histogram within output\n",
    "Nb, bins, patches = ax.hist(r, bins=100, color=\"#777777\") #initial color of all bins\n",
    "\n",
    "# for bin_size, bin, patch in zip(Nb, bins, patches):\n",
    "#     if bin_size == 100:\n",
    "#         patch.set_facecolor(\"#FF000\")\n",
    "#         patch.set_label(\"something\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "m = 3 # how much we round\n",
    "t = PrettyTable(['pr.distr.', 'mean', 'sd', '92.5%', '95%', '97.5%', '99%', '99.9%'])\n",
    "t.add_row(['Fréchet',\n",
    "           \"%.3f\" % round(np.mean(r),m),\n",
    "           \"%.3f\" % round(np.std(r),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 2.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 25),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 50),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 92.5),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 95),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 97.5),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 99),m),\n",
    "           \"%.3f\" % round(np.percentile(r, 99.9),m)])\n",
    "# t.add_row(['Bob', 19])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a function to get a excesses\n",
    "def k_greatest_values(a,k):\n",
    "    \"\"\"returns k greatest elements from the list and k-1 value starting from which we consider values to be extreme\"\"\"\n",
    "    u = np.sort(a, axis=None)[-1-k]\n",
    "    a = np.sort(a, axis=None)[-1-k+1:]\n",
    "    a = asarray([a-u for x in a])\n",
    "    return(a[1].tolist(), u) # u the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of convienience we create a function to make plots of traceplot and histogram (code will be easier to read)\n",
    "def plot(traceplot, param, distr):\n",
    "    fig, ax = plt.subplots(1, 2, sharey=True, figsize=[14,8])\n",
    "    # set x-axis name\n",
    "    ax[0].set_xlabel(\"number of iteration\")\n",
    "    ax[0].plot(traceplot)\n",
    "    ax[0].set_ylabel(\"value of \" + param)\n",
    "    # set y-axis name\n",
    "    ax[1].set_xlabel(\"quantity of records\")\n",
    "    # ax[1].set_ylabel(\"number of records\")\n",
    "\n",
    "    plt.suptitle('traceplot with histogram of values of alpha parameter in ' + distr + ' fitted to the excesses from Fréchet')\n",
    "    # titles of subplots, here we don't use it \n",
    "    # ax[0].set_title(\"traceplot of beta in GPD(alpha, beta)\")\n",
    "    # ax[1].set_title(\"Values of beta in GPD(alpha, beta) fitted to the excesses from Frechet \")\n",
    "\n",
    "    # create histogram within output\n",
    "    Nb, bins, patches = ax[1].hist(traceplot, bins=50, color=\"#777777\",  orientation=\"horizontal\") #initial color of all bins\n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100 # number of excesses\n",
    "frechet, u = k_greatest_values(r, k)\n",
    "# frechet # so we recover  k = 100 excesses sampled from Frechet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y, real alpha, real beta) {\n",
    "      return -(alpha + 1)*( log(1+y/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  \n",
    "  real myBetaPrior(real x, real beta) {\n",
    "      return -log(beta); // log(1/beta) = log(1) - log(beta) = - log(beta)\n",
    "  }\n",
    "  \n",
    "  \n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors; no priors - we assume improper priors on params\n",
    "  alpha ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher = \"\"\"\n",
    "functions { \n",
    " real myFisher_lpdf(real y, real alpha1, real alpha2, real beta) {\n",
    "      return -lbeta(alpha1,alpha2)-log(beta)+(alpha1-1)*log(y/beta)-(alpha1+alpha2)*log(1+y/beta);\n",
    "  }\n",
    "  \n",
    "// to recover more general distribution of Fisher parametrized by three parameters we need to multiply the above distribution \n",
    "// by: df1**df1/2\n",
    "// we have alpha1,2 = df1,2/2, beta = df2/df1\n",
    "}\n",
    "\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from fisher in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  //parameters of the Fisher\n",
    "  //real df1;\n",
    "  //real df2;\n",
    "  real<lower=0> alpha1;\n",
    "  real<lower=0> alpha2;\n",
    "  real<lower=0> beta;\n",
    "  \n",
    "}\n",
    "model {\n",
    "  // when we deliberately do not specify priors then Stan works with improper priors\n",
    "  alpha1 ~ gamma(1,1);\n",
    "  alpha2 ~ gamma(1,1);\n",
    "  beta ~ 1/beta;  //gamma(1,1);\n",
    "   // Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myFisher_lpdf( y[n] |alpha1, alpha2, beta);\n",
    "  }\n",
    "}\n",
    "\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N = k,  y = frechet) \n",
    "fit = StanModel(model_code=GPD).sampling(data=data,iter=1000,warmup=200, chains=1) #we sample from the provided data ;\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceplot_beta_GPD = list(fit.extract().values())[1].tolist() \n",
    "traceplot_alpha = list(fit.extract().values())[0].tolist()\n",
    "traceplot_gamma = np.divide(np.ones(len(traceplot_alpha)), traceplot_alpha)\n",
    "beta_GPD = np.mean(list(fit.extract().values())[1].tolist())\n",
    "alpha = np.mean(list(fit.extract().values())[0].tolist())\n",
    "gamma = 1 / alpha \n",
    "print(\" alpha = \", alpha, \"\\n beta = \", beta, \"\\n gamma = \", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = \"GPD(alpha, beta)\"\n",
    "plot(traceplot_alpha, \"alpha\", distr)\n",
    "plot(traceplot_beta_GPD, \"beta\", distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check different levels of quantiles to compare them with the original ones in the pretty table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N = k,  y = frechet) \n",
    "fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) #we sample from the provided data ;\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "print(\" alpha1 = \", alpha1, \"\\n alpha2 = \", alpha2, \"\\n beta = \", beta)\n",
    "# gamma = 1 / alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = \"Fischer(alpha1, alpha2, beta)\"\n",
    "plot(traceplot_alpha1, \"alpha1\", distr)\n",
    "plot(traceplot_alpha2, \"alpha2\", distr)\n",
    "plot(traceplot_beta, \"beta\", distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again we plot quantiles from the beginning to be able to compare\n",
    "print(t)\n",
    "# compare with the theeratical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theoretical quantiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the values we will use to obtain quantiles \n",
    "# values_GPD = [\" N = \", N,\" k = \",  k,\" beta = \",  beta,\" gamma = \",  gamma, \" u = \", u]\n",
    "\n",
    "# q = [0.925, 0.95, 0.975, 0.99, 0.999]\n",
    "# quant_GPD = np.zeros(len(q)) \n",
    "# for i in range(len(q)):\n",
    "#     quant_GPD[i] = u + beta_GPD*( pow( N * (1-q[i]) / k, -gamma ) - 1 ) \n",
    "# print(quant_GPD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = [0.025, 0.25, 0.5, 0.75, 0.975]# to check other values such as p = 0.025, 0.25, 0.5, 0.75, 0.975\n",
    "quant_Fischer = np.zeros(len(q))\n",
    "beta0 = alpha2 / alpha1\n",
    "\n",
    "for i in range(len(q)):\n",
    "#     q[i] = N * p[i] / k\n",
    "#     print(q[i])\n",
    "    quant_Fischer[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "print(quant_Fischer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" beta0 = \", beta0, \"\\n beta = \", beta, \"\\n beta0 / beta = \" , beta0/beta, \"\\n beta / beta0 = \", beta/beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if the quantiles are correct we need to average the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Bayesian way of obtaining the quantiles, we start with quantile estimation for GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each data set r_i, i \\in 1, ..., 20 fit GPD and using parameters obtained calculate the quantiles of bayes_GPD, GPD, \n",
    "# for each data set r_i, i \\in 1, ..., 20 fit Fisher and using parameters obtained calculate the quantiles of bayes_Fisher, Fisher, \n",
    "\n",
    "\n",
    "def quantiles_GPD(r): \n",
    "    \"\"\" \n",
    "    r is the data sample, n is the number of repetiotions of a sample, we need it to return the values \n",
    "    of fitted distribution parameters\n",
    "    \"\"\"\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_GPD = np.zeros(len(q)) \n",
    "    bayesian_quant_GPD = np.zeros(len(q))\n",
    "    \n",
    "    k = 100 # number of excesses\n",
    "    frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = frechet) \n",
    "    fit = StanModel(model_code=GPD).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate GPD quantiles and their traceplots to calculate Bayesian GPD quantiles\n",
    "    traceplot_beta_GPD = list(fit.extract().values())[1].tolist() \n",
    "    traceplot_alpha = list(fit.extract().values())[0].tolist()\n",
    "    traceplot_gamma = np.divide(np.ones(len(traceplot_alpha)), traceplot_alpha)\n",
    "    beta_GPD = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    gamma = 1 / alpha \n",
    "    \n",
    "    # we also want to keep track of parameters from each fit\n",
    "#     values_of_beta_GPD = np.zeros(n)\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_GPD[i] = u + beta_GPD*( pow( N * (1-q[i]) / k, -gamma ) - 1 ) \n",
    "        for j in range(len(traceplot_gamma)):\n",
    "                bayesian_quant_GPD[i] = bayesian_quant_GPD[i] + u + traceplot_beta_GPD[j] * (pow( N * (1 - q[i]) / k, - traceplot_gamma[j] ) - 1)\n",
    "    bayesian_quant_GPD = bayesian_quant_GPD / len(traceplot_gamma)\n",
    "    return(quant_GPD, bayesian_quant_GPD, alpha, beta_GPD ) # it return arrays: quant_GPD, bayesian_quant_GPD and values alpha, beta_GPD\n",
    "\n",
    "# now the same as above but for Fisher quantiles\n",
    "def quantiles_Fisher(r):\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_Fisher = np.zeros(len(q)) \n",
    "    bayesian_quant_Fisher = np.zeros(len(q))\n",
    "    \n",
    "    k = 100 # number of excesses\n",
    "    frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = frechet) \n",
    "    fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate Fisher quantiles and their traceplots to calculate Bayesian Fisher quantiles\n",
    "    traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "    traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "    traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "    beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "    alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    beta0 = alpha2/alpha1\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_Fisher[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "        for j in range(len(traceplot_alpha1)):\n",
    "                bayesian_quant_Fisher[i] = bayesian_quant_Fisher[i] + u + traceplot_alpha2[j] / traceplot_alpha1[j] / traceplot_beta[j] * f.isf(N / k *(1- q[i]), 2 * traceplot_alpha1[j], 2 * traceplot_alpha2[j], loc=0, scale=1)\n",
    "    bayesian_quant_Fisher = bayesian_quant_Fisher / len(traceplot_alpha1)\n",
    "    return(quant_Fisher, bayesian_quant_Fisher, alpha1, alpha2, beta) # it return arrays: quant_Fisher, bayesian_quant_Fisher and values of params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_99b4998d1842281a012eabc029de8213 NOW.\n",
      "C:\\Users\\Michal Lewandowski\\Anaconda3\\envs\\py35\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_99b4998d1842281a012eabc029de8213 NOW.\n",
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_99b4998d1842281a012eabc029de8213 NOW.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4103b09eba8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0maveraged_quant_GPD\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0maveraged_quant_GPD\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquantiles_GPD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0maveraged_bayesian_quant_GPD\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0maveraged_bayesian_quant_GPD\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquantiles_GPD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mvalues_alpha_GPD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_beta_GPD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquantiles_GPD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquantiles_GPD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0maveraged_quant_Fisher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maveraged_quant_Fisher\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquantiles_Fisher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "N, beta = 1000,  1/2\n",
    "q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "n = 2 # number of sampled dataset over which we average the quantiles\n",
    "averaged_quant_GPD, averaged_bayesian_quant_GPD = np.zeros(len(q)), np.zeros(len(q)) # initialize the values of quantiles\n",
    "averaged_quant_Fisher, averaged_bayesian_quant_Fisher = np.zeros(len(q)), np.zeros(len(q))\n",
    "values_alpha_GPD, values_beta_GPD, values_alpha1_Fisher, values_alpha2_Fisher, values_beta_Fisher = np.zeros(n), np.zeros(n), np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "for i in range(n):\n",
    "    r = frechet.rvs(beta, size=N)\n",
    "    # save the values of results of quantiles funciotns instead of calling them two times !\n",
    "    \n",
    "    averaged_quant_GPD  = averaged_quant_GPD + quantiles_GPD(r)[0]\n",
    "    averaged_bayesian_quant_GPD =  averaged_bayesian_quant_GPD + quantiles_GPD(r)[1]\n",
    "    values_alpha_GPD[i], values_beta_GPD[i] = quantiles_GPD(r)[2], quantiles_GPD(r)[3]\n",
    "    \n",
    "    averaged_quant_Fisher = averaged_quant_Fisher + quantiles_Fisher(r)[0] \n",
    "    averaged_bayesian_quant_Fisher = averaged_bayesian_quant_Fisher + quantiles_Fisher(r)[1]\n",
    "    values_alpha1_Fisher[i], values_alpha2_Fisher[i], values_beta_Fisher[i] = quantiles_Fisher(r)[2], quantiles_Fisher(r)[3], quantiles_Fisher(r)[4]\n",
    "\n",
    "averaged_quant_GPD, averaged_bayesian_quant_GPD = averaged_quant_GPD / n, averaged_bayesian_quant_GPD / n\n",
    "averaged_quant_Fisher, averaged_bayesian_quant_Fisher = averaged_quant_Fisher / n, averaged_bayesian_quant_Fisher / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.58145741  4.41539644  6.2847347   9.97492669 31.6148686 ]\n"
     ]
    }
   ],
   "source": [
    "quant_th = np.ones(len(q))\n",
    "for i in range(len(quant_th)):\n",
    "    quant_th[i] = pow(-log(q[i]), -1/2)\n",
    "print(quant_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.49588436  4.28529461  6.23689473 10.66791151 46.16304893] \n",
      " [ 3.4928419   4.28351695  6.27605515 10.98678999 55.21997139] \n",
      " [ 3.32017793  3.73330386  4.73449301  7.01646274 25.82149899] \n",
      " [ 3.32716783  3.75346773  4.84723931  7.61752349 40.15698042]\n"
     ]
    }
   ],
   "source": [
    "print(averaged_quant_GPD,\"\\n\",  averaged_bayesian_quant_GPD, \"\\n\", averaged_quant_Fisher, \"\\n\", averaged_bayesian_quant_Fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters of GPD and Fisher for every fit \n",
    "\n",
    "# bayesian_quantile_gpd = np.zeros(len(q))\n",
    "\n",
    "# for j in range(len(q)):\n",
    "#     for i in range(len(traceplot_gamma)):\n",
    "#         bayesian_quantile_gpd[j] = bayesian_quantile_gpd[j] + u + traceplot_beta_GPD[i] * (pow( N * (1 - q[j]) / k, - traceplot_gamma[i] ) - 1)\n",
    "# bayesian_quantile_gpd = bayesian_quantile_gpd / len(traceplot_gamma)\n",
    "# bayesian_quantile_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian_quantile_fisher = np.zeros(len(q))\n",
    "# # u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "# for j in range(len(q)):\n",
    "#     for i in range(len(traceplot_alpha1)):\n",
    "#         bayesian_quantile_fisher[j] = bayesian_quantile_fisher[j] + u + traceplot_alpha2[i] / traceplot_alpha1[i] / traceplot_beta[i] * f.isf(N / k *(1- q[j]), 2 * traceplot_alpha1[i], 2 * traceplot_alpha2[i], loc=0, scale=1)\n",
    "# bayesian_quantile_fisher = bayesian_quantile_fisher / len(traceplot_alpha1)\n",
    "# bayesian_quantile_fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '0.9', '0.95', '0.975', '0.99', '0.999'\n",
    "\n",
    "t_quantiles = PrettyTable(['how obtained',  'mean', 'sd', '92.5%', '95%', '97.5%', '99%', '99.9%'])\n",
    "# t_quantiles.add_row(['numpy', \n",
    "#            \"%.3f\" % round(np.mean(r),m),\n",
    "#            \"%.3f\" % round(np.std(r),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 92.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 95),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 97.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 99),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 99.9),m)])\n",
    "t_quantiles.add_row(['theoretically', '--', '--',\n",
    "                     \"%.3f\" % round(quant_th[0],m),  \n",
    "                     \"%.3f\" % round(quant_th[1], m), \n",
    "                     \"%.3f\" % round(quant_th[2], m),\n",
    "                     \"%.3f\" % round(quant_th[3], m),\n",
    "                     \"%.3f\" % round(quant_th[4], m) ])\n",
    "t_quantiles.add_row(['Bayes Fisher',  '--', '--',\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[0],m),  \n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[1], m), \n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[2], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[3], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[4], m) ])\n",
    "t_quantiles.add_row([' Fisher',  '--', '--',\n",
    "                     \"%.3f\" % round(quant_Fischer[0],m),  \n",
    "                     \"%.3f\" % round(quant_Fischer[1], m), \n",
    "                     \"%.3f\" % round(quant_Fischer[2], m),\n",
    "                     \"%.3f\" % round(quant_Fischer[3], m),\n",
    "                     \"%.3f\" % round(quant_Fischer[4], m) ])\n",
    "t_quantiles.add_row([' Bayes GPD', '--', '--',\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[0],m),  \n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[1], m), \n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[2], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[3], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[4], m) ])\n",
    "t_quantiles.add_row(['  GPD',  '--', '--',\n",
    "                     \"%.3f\" % round(quant_GPD[0],m),  \n",
    "                     \"%.3f\" % round(quant_GPD[1], m), \n",
    "                     \"%.3f\" % round(quant_GPD[2], m),\n",
    "                     \"%.3f\" % round(quant_GPD[3], m),\n",
    "                     \"%.3f\" % round(quant_GPD[4], m) ])\n",
    "# t.add_row(['Bob', 19])\n",
    "print(t_quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
