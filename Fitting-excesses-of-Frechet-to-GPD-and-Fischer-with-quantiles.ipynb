{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "from pystan import StanModel \n",
    "from numpy import polyval, place, extract, any, asarray, nan, inf, pi\n",
    "from numpy import (where, arange, putmask, ravel, sum, shape,\n",
    "                   log, sqrt, exp, arctanh, tan, sin, arcsin, arctan,\n",
    "                   tanh, cos, cosh, sinh, log1p, expm1)\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import f\n",
    "\n",
    "\n",
    "class frechet_gen(rv_continuous):\n",
    "#     def _argcheck(self, c):\n",
    "#         c = asarray(c)\n",
    "#         self.b = where(c < 0, 1.0/abs(c), inf)\n",
    "#         return where(c == 0, 0, 1)\n",
    "\n",
    "#     def _pdf(self, x, alpha1, alpha2, beta):\n",
    "#         Px = 1 / beta / ss.beta(alpha1, alpha2) * pow(x/beta, asarray(alpha1-1.0)) * pow(1 + x/beta, asarray(- alpha1 - alpha2))\n",
    "#         return Px\n",
    "\n",
    "#     def _logpdf(self, x, alpha1, alpha2, beta):\n",
    "#         return (alpha1 - 1) * np.log(x) - alpha1 * np.log(beta) - np.log(ss.beta(alpha1, alpha2)) - (alpha1 + alpha2) * np.log(1 + x/beta)\n",
    "\n",
    "    def _cdf(self, x, beta):\n",
    "        return exp(-pow(x, -1/beta))\n",
    "#     def _ppf(self, q, c):\n",
    "#         vals = 1.0/c * (pow(1-q, -c)-1)\n",
    "#         return vals\n",
    "\n",
    "#     def _munp(self, n, c):\n",
    "#         k = arange(0, n+1)\n",
    "#         val = (-1.0/c)**n * sum(comb(n, k)*(-1)**k / (1.0-c*k), axis=0)\n",
    "#         return where(c*n < 1, val, inf)\n",
    "\n",
    "#     def _entropy(self, c):\n",
    "#         if (c > 0):\n",
    "#             return 1+c\n",
    "#         else:\n",
    "#             self.b = -1.0 / c\n",
    "#             return rv_continuous._entropy(self, c)\n",
    "frechet = frechet_gen(a=0.0, name='frechet') # we specify the support [a,b], no b means b = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are able to sample rv exactly as in publication\n",
    "N, beta = 1000,  1/2 # run with n = 1000000\n",
    "# beta = 1/2 because we want to have a finite mean and for this beta we could check that the code is good\n",
    "r = frechet.rvs(beta, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of data\n",
    "fig, ax = plt.subplots(figsize=[8,6])\n",
    "\n",
    "# set plot title\n",
    "ax.set_title(\"Data sampled from Frechet \")\n",
    "\n",
    "# set x-axis name\n",
    "ax.set_xlabel(\"value\")\n",
    "\n",
    "# set y-axis name\n",
    "ax.set_ylabel(\"number of records\")\n",
    "\n",
    "# create histogram within output\n",
    "Nb, bins, patches = ax.hist(r, bins=100, color=\"#777777\") #initial color of all bins\n",
    "\n",
    "# for bin_size, bin, patch in zip(Nb, bins, patches):\n",
    "#     if bin_size == 100:\n",
    "#         patch.set_facecolor(\"#FF000\")\n",
    "#         patch.set_label(\"something\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "m = 3 # how much we round\n",
    "t = PrettyTable(['pr.distr.', 'mean', 'sd', '92.5%', '95%', '97.5%', '99%', '99.9%'])\n",
    "t.add_row(['Fréchet',\n",
    "           \"%.3f\" % round(np.mean(r),m),\n",
    "           \"%.3f\" % round(np.std(r),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 2.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 25),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 50),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 92.5),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 95),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 97.5),m), \n",
    "           \"%.3f\" % round(np.percentile(r, 99),m),\n",
    "           \"%.3f\" % round(np.percentile(r, 99.9),m)])\n",
    "# t.add_row(['Bob', 19])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a function to get a excesses\n",
    "def k_greatest_values(a,k):\n",
    "    \"\"\"returns k greatest elements from the list and k-1 value starting from which we consider values to be extreme\"\"\"\n",
    "    u = np.sort(a, axis=None)[-1-k]\n",
    "    a = np.sort(a, axis=None)[-1-k+1:]\n",
    "    a = asarray([a-u for x in a])\n",
    "    return(a[1].tolist(), u) # u the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function to make plots of traceplot and horizontal histogram of the traceplot in one row\n",
    "def plot(traceplot, param, distr):\n",
    "    fig, ax = plt.subplots(1, 2, sharey=True, figsize=[14,8])\n",
    "    # set x-axis name\n",
    "    ax[0].set_xlabel(\"number of iteration\")\n",
    "    ax[0].plot(traceplot)\n",
    "    ax[0].set_ylabel(\"value of \" + param)\n",
    "    # set y-axis name\n",
    "    ax[1].set_xlabel(\"quantity of records\")\n",
    "    # ax[1].set_ylabel(\"number of records\")\n",
    "\n",
    "    plt.suptitle('traceplot with histogram of values of alpha parameter in ' + distr + ' fitted to the excesses from Fréchet')\n",
    "    # titles of subplots, here we don't use it \n",
    "    # ax[0].set_title(\"traceplot of beta in GPD(alpha, beta)\")\n",
    "    # ax[1].set_title(\"Values of beta in GPD(alpha, beta) fitted to the excesses from Frechet \")\n",
    "\n",
    "    # create histogram within output\n",
    "    Nb, bins, patches = ax[1].hist(traceplot, bins=50, color=\"#777777\",  orientation=\"horizontal\") #initial color of all bins\n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100 # number of excesses\n",
    "frechet, u = k_greatest_values(r, k)\n",
    "# frechet # so we recover  k = 100 excesses sampled from Frechet distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y, real alpha, real beta) {\n",
    "      return -(alpha + 1)*( log(1+y/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  \n",
    "  real myBetaPrior(real x, real beta) {\n",
    "      return -log(beta); // log(1/beta) = log(1) - log(beta) = - log(beta)\n",
    "  }\n",
    "  \n",
    "  \n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors; no priors - we assume improper priors on params\n",
    "  alpha ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher = \"\"\"\n",
    "functions { \n",
    " real myFisher_lpdf(real y, real alpha1, real alpha2, real beta) {\n",
    "      return -lbeta(alpha1,alpha2)-log(beta)+(alpha1-1)*log(y/beta)-(alpha1+alpha2)*log(1+y/beta);\n",
    "  }\n",
    "  \n",
    "// to recover more general distribution of Fisher parametrized by three parameters we need to multiply the above distribution \n",
    "// by: df1**df1/2\n",
    "// we have alpha1,2 = df1,2/2, beta = df2/df1\n",
    "}\n",
    "\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from fisher in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  //parameters of the Fisher\n",
    "  //real df1;\n",
    "  //real df2;\n",
    "  real<lower=0> alpha1;\n",
    "  real<lower=0> alpha2;\n",
    "  real<lower=0> beta;\n",
    "  \n",
    "}\n",
    "model {\n",
    "  // when we deliberately do not specify priors then Stan works with improper priors\n",
    "  alpha1 ~ gamma(1,1);\n",
    "  alpha2 ~ gamma(1,1);\n",
    "  beta ~ 1/beta;  //gamma(1,1);\n",
    "   // Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myFisher_lpdf( y[n] |alpha1, alpha2, beta);\n",
    "  }\n",
    "}\n",
    "\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N = k,  y = frechet) \n",
    "fit = StanModel(model_code=GPD).sampling(data=data,iter=1000,warmup=200, chains=1) #we sample from the provided data ;\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceplot_beta_GPD = list(fit.extract().values())[1].tolist() \n",
    "traceplot_alpha = list(fit.extract().values())[0].tolist()\n",
    "traceplot_gamma = np.divide(np.ones(len(traceplot_alpha)), traceplot_alpha)\n",
    "beta_GPD = np.mean(list(fit.extract().values())[1].tolist())\n",
    "alpha = np.mean(list(fit.extract().values())[0].tolist())\n",
    "gamma = 1 / alpha \n",
    "print(\" alpha = \", alpha, \"\\n beta = \", beta, \"\\n gamma = \", gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = \"GPD(alpha, beta)\"\n",
    "plot(traceplot_alpha, \"alpha\", distr)\n",
    "plot(traceplot_beta_GPD, \"beta\", distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check different levels of quantiles to compare them with the original ones in the pretty table above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N = k,  y = frechet) \n",
    "fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) #we sample from the provided data ;\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "print(\" alpha1 = \", alpha1, \"\\n alpha2 = \", alpha2, \"\\n beta = \", beta)\n",
    "# gamma = 1 / alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = \"Fischer(alpha1, alpha2, beta)\"\n",
    "plot(traceplot_alpha1, \"alpha1\", distr)\n",
    "plot(traceplot_alpha2, \"alpha2\", distr)\n",
    "plot(traceplot_beta, \"beta\", distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once again we plot quantiles from the beginning to be able to compare\n",
    "print(t)\n",
    "# compare with the theeratical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theoretical quantiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the values we will use to obtain quantiles \n",
    "# values_GPD = [\" N = \", N,\" k = \",  k,\" beta = \",  beta,\" gamma = \",  gamma, \" u = \", u]\n",
    "\n",
    "# q = [0.925, 0.95, 0.975, 0.99, 0.999]\n",
    "# quant_GPD = np.zeros(len(q)) \n",
    "# for i in range(len(q)):\n",
    "#     quant_GPD[i] = u + beta_GPD*( pow( N * (1-q[i]) / k, -gamma ) - 1 ) \n",
    "# print(quant_GPD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = [0.025, 0.25, 0.5, 0.75, 0.975]# to check other values such as p = 0.025, 0.25, 0.5, 0.75, 0.975\n",
    "quant_Fischer = np.zeros(len(q))\n",
    "beta0 = alpha2 / alpha1\n",
    "\n",
    "for i in range(len(q)):\n",
    "#     q[i] = N * p[i] / k\n",
    "#     print(q[i])\n",
    "    quant_Fischer[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "print(quant_Fischer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" beta0 = \", beta0, \"\\n beta = \", beta, \"\\n beta0 / beta = \" , beta0/beta, \"\\n beta / beta0 = \", beta/beta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if the quantiles are correct we need to average the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# Bayesian way of obtaining the quantiles, we start with quantile estimation for GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each data set r_i, i \\in 1, ..., 20 fit GPD and using parameters obtained calculate the quantiles of bayes_GPD, GPD, \n",
    "# for each data set r_i, i \\in 1, ..., 20 fit Fisher and using parameters obtained calculate the quantiles of bayes_Fisher, Fisher, \n",
    "\n",
    "\n",
    "def quantiles_GPD(r): \n",
    "    \"\"\" \n",
    "    r is the data sample\n",
    "    \"\"\"\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_GPD = np.zeros(len(q)) \n",
    "    bayesian_quant_GPD = np.zeros(len(q))\n",
    "    \n",
    "    k = 100 # number of excesses\n",
    "    frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = frechet) \n",
    "    fit = StanModel(model_code=GPD).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate GPD quantiles and their traceplots to calculate Bayesian GPD quantiles\n",
    "    traceplot_beta_GPD = list(fit.extract().values())[1].tolist() \n",
    "    traceplot_alpha = list(fit.extract().values())[0].tolist()\n",
    "    traceplot_gamma = np.divide(np.ones(len(traceplot_alpha)), traceplot_alpha)\n",
    "    beta_GPD = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    gamma = 1 / alpha \n",
    "    \n",
    "    # we also want to keep track of parameters from each fit\n",
    "#     values_of_beta_GPD = np.zeros(n)\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_GPD[i] = u + beta_GPD*( pow( N * (1-q[i]) / k, -gamma ) - 1 ) \n",
    "        for j in range(len(traceplot_gamma)):\n",
    "                bayesian_quant_GPD[i] = bayesian_quant_GPD[i] + u + traceplot_beta_GPD[j] * (pow( N * (1 - q[i]) / k, - traceplot_gamma[j] ) - 1)\n",
    "    bayesian_quant_GPD = bayesian_quant_GPD / len(traceplot_gamma)\n",
    "    list_of_params = [alpha, beta_GPD]\n",
    "    return(quant_GPD, bayesian_quant_GPD, list_of_params ) # it return arrays: quant_GPD, bayesian_quant_GPD and values alpha, beta_GPD\n",
    "\n",
    "# now the same as above but for Fisher quantiles\n",
    "def quantiles_Fisher(r):\n",
    "    q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "    quant_Fisher = np.zeros(len(q)) \n",
    "    bayesian_quant_Fisher = np.zeros(len(q))\n",
    "    \n",
    "    k = 100 # number of excesses\n",
    "    frechet, u = k_greatest_values(r, k)\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = frechet) \n",
    "    fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate Fisher quantiles and their traceplots to calculate Bayesian Fisher quantiles\n",
    "    traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "    traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "    traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "    beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "    alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    beta0 = alpha2/alpha1\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_Fisher[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "        for j in range(len(traceplot_alpha1)):\n",
    "                bayesian_quant_Fisher[i] = bayesian_quant_Fisher[i] + u + traceplot_alpha2[j] / traceplot_alpha1[j] / traceplot_beta[j] * f.isf(N / k *(1- q[i]), 2 * traceplot_alpha1[j], 2 * traceplot_alpha2[j], loc=0, scale=1)\n",
    "    bayesian_quant_Fisher = bayesian_quant_Fisher / len(traceplot_alpha1)\n",
    "    return(quant_Fisher, bayesian_quant_Fisher, alpha1, alpha2, beta) # it return arrays: quant_Fisher, bayesian_quant_Fisher and values of params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what does the function returns, maybe there is no need to call it several times and we can get by with just one call?\n",
    "N, beta = 1000,  1/2\n",
    "q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "n = 1 # number of sampled dataset over which we average the quantiles\n",
    "averaged_quant_GPD, averaged_bayesian_quant_GPD, params_GPD = np.ones(len(q)), np.ones(len(q)), np.ones(2) # initialize the values of quantiles\n",
    "# averaged_quant_Fisher, averaged_bayesian_quant_Fisher = np.zeros(len(q)), np.zeros(len(q))\n",
    "# values_alpha_GPD, values_beta_GPD, values_alpha1_Fisher, values_alpha2_Fisher, values_beta_Fisher = np.ones(n), np.ones(n), np.zeros(n), np.zeros(n), np.zeros(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.] [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(averaged_quant_GPD, averaged_bayesian_quant_GPD, params_GPD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1561b2fac3108872ed6bafb6d2492041 NOW.\n",
      "C:\\Users\\Michal Lewandowski\\Anaconda3\\envs\\py35\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    }
   ],
   "source": [
    "r = frechet.rvs(beta, size=N)\n",
    "k = 100 # number of excesses\n",
    "frechet, u = k_greatest_values(r, k)\n",
    "\n",
    "new_averaged_quant_GPD, new_averaged_bayesian_quant_GPD, params_GPD = quantiles_GPD(r)\n",
    "# averaged_quant_GPD, averaged_bayesian_quant_GPD, values_alpha_GPD, values_beta_GPD += new_averaged_quant_GPD, new_averaged_bayesian_quant_GPD, new_values_alpha_GPD, new_values_beta_GPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.] [1. 1. 1. 1. 1.] {1.9942238730065611, 2.9728366993225666}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-247b173f8111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveraged_quant_GPD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maveraged_bayesian_quant_GPD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_GPD\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparams_GPD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object does not support indexing"
     ]
    }
   ],
   "source": [
    "print(averaged_quant_GPD, averaged_bayesian_quant_GPD, params_GPD )\n",
    "params_GPD[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, so there is no need to call the function several times using quantiles_GPD(r)[1]\n",
    "# now: can we add those values to the ones already existing, not just obtain them by initialization ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bigger sample to make averaging over numeroues datasets I use the loop for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, beta = 1000,  1/2\n",
    "q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "n = 2 # number of sampled dataset over which we average the quantiles\n",
    "averaged_quant_GPD, averaged_bayesian_quant_GPD = np.zeros(len(q)), np.zeros(len(q)) # initialize the values of quantiles\n",
    "averaged_quant_Fisher, averaged_bayesian_quant_Fisher = np.zeros(len(q)), np.zeros(len(q))\n",
    "values_alpha_GPD, values_beta_GPD, values_alpha1_Fisher, values_alpha2_Fisher, values_beta_Fisher = np.zeros(n), np.zeros(n), np.zeros(n), np.zeros(n), np.zeros(n)\n",
    "for i in range(n):\n",
    "    r = frechet.rvs(beta, size=N)\n",
    "    # save the values of results of quantiles funciotns instead of calling them two times !\n",
    "    \n",
    "    averaged_quant_GPD  = averaged_quant_GPD + quantiles_GPD(r)[0]\n",
    "    averaged_bayesian_quant_GPD =  averaged_bayesian_quant_GPD + quantiles_GPD(r)[1]\n",
    "    values_alpha_GPD[i], values_beta_GPD[i] = quantiles_GPD(r)[2], quantiles_GPD(r)[3]\n",
    "    \n",
    "    averaged_quant_Fisher = averaged_quant_Fisher + quantiles_Fisher(r)[0] \n",
    "    averaged_bayesian_quant_Fisher = averaged_bayesian_quant_Fisher + quantiles_Fisher(r)[1]\n",
    "    values_alpha1_Fisher[i], values_alpha2_Fisher[i], values_beta_Fisher[i] = quantiles_Fisher(r)[2], quantiles_Fisher(r)[3], quantiles_Fisher(r)[4]\n",
    "\n",
    "averaged_quant_GPD, averaged_bayesian_quant_GPD = averaged_quant_GPD / n, averaged_bayesian_quant_GPD / n\n",
    "averaged_quant_Fisher, averaged_bayesian_quant_Fisher = averaged_quant_Fisher / n, averaged_bayesian_quant_Fisher / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_th = np.ones(len(q))\n",
    "for i in range(len(quant_th)):\n",
    "    quant_th[i] = pow(-log(q[i]), -1/2)\n",
    "print(quant_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(averaged_quant_GPD,\"\\n\",  averaged_bayesian_quant_GPD, \"\\n\", averaged_quant_Fisher, \"\\n\", averaged_bayesian_quant_Fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters of GPD and Fisher for every fit \n",
    "\n",
    "# bayesian_quantile_gpd = np.zeros(len(q))\n",
    "\n",
    "# for j in range(len(q)):\n",
    "#     for i in range(len(traceplot_gamma)):\n",
    "#         bayesian_quantile_gpd[j] = bayesian_quantile_gpd[j] + u + traceplot_beta_GPD[i] * (pow( N * (1 - q[j]) / k, - traceplot_gamma[i] ) - 1)\n",
    "# bayesian_quantile_gpd = bayesian_quantile_gpd / len(traceplot_gamma)\n",
    "# bayesian_quantile_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian_quantile_fisher = np.zeros(len(q))\n",
    "# # u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "# for j in range(len(q)):\n",
    "#     for i in range(len(traceplot_alpha1)):\n",
    "#         bayesian_quantile_fisher[j] = bayesian_quantile_fisher[j] + u + traceplot_alpha2[i] / traceplot_alpha1[i] / traceplot_beta[i] * f.isf(N / k *(1- q[j]), 2 * traceplot_alpha1[i], 2 * traceplot_alpha2[i], loc=0, scale=1)\n",
    "# bayesian_quantile_fisher = bayesian_quantile_fisher / len(traceplot_alpha1)\n",
    "# bayesian_quantile_fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '0.9', '0.95', '0.975', '0.99', '0.999'\n",
    "\n",
    "t_quantiles = PrettyTable(['how obtained',  'mean', 'sd', '92.5%', '95%', '97.5%', '99%', '99.9%'])\n",
    "# t_quantiles.add_row(['numpy', \n",
    "#            \"%.3f\" % round(np.mean(r),m),\n",
    "#            \"%.3f\" % round(np.std(r),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 92.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 95),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 97.5),m), \n",
    "#            \"%.3f\" % round(np.percentile(r, 99),m),\n",
    "#            \"%.3f\" % round(np.percentile(r, 99.9),m)])\n",
    "t_quantiles.add_row(['theoretically', '--', '--',\n",
    "                     \"%.3f\" % round(quant_th[0],m),  \n",
    "                     \"%.3f\" % round(quant_th[1], m), \n",
    "                     \"%.3f\" % round(quant_th[2], m),\n",
    "                     \"%.3f\" % round(quant_th[3], m),\n",
    "                     \"%.3f\" % round(quant_th[4], m) ])\n",
    "t_quantiles.add_row(['Bayes Fisher',  '--', '--',\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[0],m),  \n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[1], m), \n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[2], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[3], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_fisher[4], m) ])\n",
    "t_quantiles.add_row([' Fisher',  '--', '--',\n",
    "                     \"%.3f\" % round(quant_Fischer[0],m),  \n",
    "                     \"%.3f\" % round(quant_Fischer[1], m), \n",
    "                     \"%.3f\" % round(quant_Fischer[2], m),\n",
    "                     \"%.3f\" % round(quant_Fischer[3], m),\n",
    "                     \"%.3f\" % round(quant_Fischer[4], m) ])\n",
    "t_quantiles.add_row([' Bayes GPD', '--', '--',\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[0],m),  \n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[1], m), \n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[2], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[3], m),\n",
    "                     \"%.3f\" % round(bayesian_quantile_gpd[4], m) ])\n",
    "t_quantiles.add_row(['  GPD',  '--', '--',\n",
    "                     \"%.3f\" % round(quant_GPD[0],m),  \n",
    "                     \"%.3f\" % round(quant_GPD[1], m), \n",
    "                     \"%.3f\" % round(quant_GPD[2], m),\n",
    "                     \"%.3f\" % round(quant_GPD[3], m),\n",
    "                     \"%.3f\" % round(quant_GPD[4], m) ])\n",
    "# t.add_row(['Bob', 19])\n",
    "print(t_quantiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
