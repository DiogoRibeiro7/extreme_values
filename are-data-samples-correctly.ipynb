{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "from pystan import StanModel \n",
    "from numpy import polyval, place, extract, any, asarray, nan, inf, pi\n",
    "from numpy import (where, arange, putmask, ravel, sum, shape,\n",
    "                   log, sqrt, exp, arctanh, tan, sin, arcsin, arctan,\n",
    "                   tanh, cos, cosh, sinh, log1p, expm1)\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import f\n",
    "# from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frechet_gen(rv_continuous):\n",
    "#     def _argcheck(self, c):\n",
    "#         c = asarray(c)\n",
    "#         self.b = where(c < 0, 1.0/abs(c), inf)\n",
    "#         return where(c == 0, 0, 1)\n",
    "\n",
    "#     def _pdf(self, x, alpha1, alpha2, beta):\n",
    "#         Px = 1 / beta / ss.beta(alpha1, alpha2) * pow(x/beta, asarray(alpha1-1.0)) * pow(1 + x/beta, asarray(- alpha1 - alpha2))\n",
    "#         return Px\n",
    "\n",
    "#     def _logpdf(self, x, alpha1, alpha2, beta):\n",
    "#         return (alpha1 - 1) * np.log(x) - alpha1 * np.log(beta) - np.log(ss.beta(alpha1, alpha2)) - (alpha1 + alpha2) * np.log(1 + x/beta)\n",
    "\n",
    "    def _cdf(self, x, beta):\n",
    "        return exp(-pow(x, -1/beta))\n",
    "#     def _ppf(self, q, c):\n",
    "#         vals = 1.0/c * (pow(1-q, -c)-1)\n",
    "#         return vals\n",
    "\n",
    "#     def _munp(self, n, c):\n",
    "#         k = arange(0, n+1)\n",
    "#         val = (-1.0/c)**n * sum(comb(n, k)*(-1)**k / (1.0-c*k), axis=0)\n",
    "#         return where(c*n < 1, val, inf)\n",
    "\n",
    "#     def _entropy(self, c):\n",
    "#         if (c > 0):\n",
    "#             return 1+c\n",
    "#         else:\n",
    "#             self.b = -1.0 / c\n",
    "#             return rv_continuous._entropy(self, c)\n",
    "frechet = frechet_gen(a=0.0, name='frechet') # we specify the support [a,b], no b means b = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_greatest_values_matrices(a,k):\n",
    "    \"\"\"returns k greatest elements from the list a and k - 1 value starting from which we consider greater values as extremes\"\"\"\n",
    "    # we prepare the matrix for the excesses, the last value of 1 could be substituted by any value within the range\n",
    "    mat = np.zeros( len(a[-1 - k + 1 : , 1] ) ) \n",
    "    # we prepare the vector in which we will return u values for each dataset in column of a\n",
    "    u = np.zeros(len(r[0 , : ] )) \n",
    "    for i in range(len(a[0,:])): \n",
    "        # index i goes through the columns, instead of len(a[0,:]) there could be len(a[i,:]) for i in range of columns\n",
    "        u[i] = a[-1 - k, i] \n",
    "        # u is a list of values s.t. bigger values are considered as excesses, for each set of data, i.e. for each column we save an u value\n",
    "        mat = np.column_stack( (mat,a[ -1 - k + 1 : , i]) ) \n",
    "    # in mat matrix we return the values of excesses but not yet transformed (y_i = x_i - u)\n",
    "    return(mat, u) # u is the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of sampled dataset over which we average the quantiles\n",
    "N, beta = 1000,  1/2\n",
    "k = 50\n",
    "\n",
    "r = frechet.rvs(beta, size=N)\n",
    "for i in range(n):\n",
    "    r = np.column_stack( (r, frechet.rvs(beta, size=N) ) ) \n",
    "\n",
    "# r = np.delete(r, 0, 1)    # delete first column with sampled data to much the sizes\n",
    "\n",
    "# we need to sort in increasing order gathered data\n",
    "for i in range(len(r[0,:])):\n",
    "    r[:,i] = np.sort(r[:,i], axis=None)# we sort data sampled from frechet, each dataset is in separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete first column (indexed by 0) of a matrix A, to match the sizes \n",
    "A = np.delete(data_frechet, 0, 1)\n",
    "\n",
    "# form the array of u values we create matrix, in columns we have repeated u values   \n",
    "B = [ [x] * k for x in u ] \n",
    "\n",
    "# here we subtract u_i from excesses in each dataset\n",
    "C = np.array(A) - np.array(B).transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y, real alpha, real beta) {\n",
    "      return -(alpha + 1)*( log(1+y/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  \n",
    "  real myBetaPrior_lpdf(real x, real beta) {\n",
    "      return -log(beta); // log(1/beta) = log(1) - log(beta) = - log(beta)\n",
    "  }\n",
    "  \n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors; no priors - we assume improper priors on params\n",
    "  alpha ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher = \"\"\"\n",
    "functions { \n",
    " real myFisher_lpdf(real y, real alpha1, real alpha2, real beta) {\n",
    "      return -lbeta(alpha1,alpha2)-log(beta)+(alpha1-1)*log(y/beta)-(alpha1+alpha2)*log(1+y/beta);\n",
    "  }\n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; \n",
    "}\n",
    "parameters { \n",
    "  //parameters of the Fisher\n",
    "  real<lower=0> alpha1;\n",
    "  real<lower=0> alpha2;\n",
    "  real<lower=0> beta; \n",
    "}\n",
    "model {\n",
    "  // when we deliberately do not specify priors then Stan works with improper priors\n",
    "  alpha1 ~ gamma(1,1);\n",
    "  alpha2 ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "   // Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myFisher_lpdf( y[n] |alpha1, alpha2, beta);\n",
    "  }\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9999999999999996\n",
      "1.0000000000000009\n",
      "0.5000000000000004\n",
      "0.20000000000000018\n",
      "0.020000000000000018\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(q)):\n",
    "    print(N / k * (1-q[i]))\n",
    "\n",
    "\n",
    "def quantiles_Fisher(excesses, k, u):\n",
    "    quant_Fisher = np.zeros(len(q)) \n",
    "    bayesian_quant_Fisher = np.zeros(len(q))\n",
    "    \n",
    "    # here we fit GPD to excesses via PyStan\n",
    "    data = dict(N = k,  y = excesses) \n",
    "    fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) \n",
    "    \n",
    "    # we save the params from the fit to calculate Fisher quantiles and their traceplots to calculate Bayesian Fisher quantiles\n",
    "    traceplot_beta = list(fit.extract().values())[2].tolist()\n",
    "    traceplot_alpha1 = list(fit.extract().values())[1].tolist()\n",
    "    traceplot_alpha2 = list(fit.extract().values())[0].tolist()\n",
    "    beta = np.mean(list(fit.extract().values())[2].tolist())\n",
    "    alpha2 = np.mean(list(fit.extract().values())[1].tolist())\n",
    "    alpha1 = np.mean(list(fit.extract().values())[0].tolist())\n",
    "    beta0 = alpha2/alpha1\n",
    "    \n",
    "    for i in range(len(q)):\n",
    "        quant_Fisher[i] = u + beta0 / beta * f.isf(N / k * (1-q[i]), 2 * alpha1, 2 * alpha2, loc=0, scale=1)\n",
    "        for j in range(len(traceplot_alpha1)):\n",
    "                bayesian_quant_Fisher[i] += u + traceplot_alpha2[j] / traceplot_alpha1[j] / traceplot_beta[j] * f.isf(N / k *(1- q[i]), 2 * traceplot_alpha1[j], 2 * traceplot_alpha2[j], loc=0, scale=1)\n",
    "    bayesian_quant_Fisher = bayesian_quant_Fisher / len(traceplot_alpha1)\n",
    "    list_of_params = [alpha1, alpha2, beta]\n",
    "    return(quant_Fisher, bayesian_quant_Fisher, list_of_params) \n",
    "# it return arrays: quant_Fisher, bayesian_quant_Fisher and values of params as a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [0.98, 0.99, 0.995, 0.999, 0.9995]\n",
    "\n",
    "quant_th = np.zeros(len(q))\n",
    "for i in range(len(q)):\n",
    "    quant_th[i] = pow(-log(q[i]), -beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 50\n"
     ]
    }
   ],
   "source": [
    "print(N, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ecbac65cce1d714e75f45a634ba1d39a NOW.\n",
      "C:\\Users\\Michal Lewandowski\\Anaconda3\\envs\\py35\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    }
   ],
   "source": [
    "# q = [0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "\n",
    "quant_Fisher, bayesian_quant_Fisher, params_Fisher = quantiles_Fisher(C[:,1], len(C[:,1]), u[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1212036   5.89201143  6.98840256 11.77965787 15.49679451] \n",
      " [ 5.84941674  7.35419255  9.42809327 18.20534311 25.03463778]\n"
     ]
    }
   ],
   "source": [
    "print(quant_Fisher,\"\\n\", bayesian_quant_Fisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
