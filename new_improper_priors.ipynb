{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "from pystan import StanModel \n",
    "from numpy import polyval, place, extract, any, asarray, nan, inf, pi\n",
    "from numpy import (where, arange, putmask, ravel, sum, shape,\n",
    "                   log, sqrt, exp, arctanh, tan, sin, arcsin, arctan,\n",
    "                   tanh, cos, cosh, sinh, log1p, expm1)\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frechet_gen(rv_continuous):\n",
    "#     def _argcheck(self, c):\n",
    "#         c = asarray(c)\n",
    "#         self.b = where(c < 0, 1.0/abs(c), inf)\n",
    "#         return where(c == 0, 0, 1)\n",
    "\n",
    "#     def _pdf(self, x, alpha1, alpha2, beta):\n",
    "#         Px = 1 / beta / ss.beta(alpha1, alpha2) * pow(x/beta, asarray(alpha1-1.0)) * pow(1 + x/beta, asarray(- alpha1 - alpha2))\n",
    "#         return Px\n",
    "\n",
    "#     def _logpdf(self, x, alpha1, alpha2, beta):\n",
    "#         return (alpha1 - 1) * np.log(x) - alpha1 * np.log(beta) - np.log(ss.beta(alpha1, alpha2)) - (alpha1 + alpha2) * np.log(1 + x/beta)\n",
    "\n",
    "    def _cdf(self, x, beta):\n",
    "        return exp(-pow(x, -1/beta))\n",
    "#     def _ppf(self, q, c):\n",
    "#         vals = 1.0/c * (pow(1-q, -c)-1)\n",
    "#         return vals\n",
    "\n",
    "#     def _munp(self, n, c):\n",
    "#         k = arange(0, n+1)\n",
    "#         val = (-1.0/c)**n * sum(comb(n, k)*(-1)**k / (1.0-c*k), axis=0)\n",
    "#         return where(c*n < 1, val, inf)\n",
    "\n",
    "#     def _entropy(self, c):\n",
    "#         if (c > 0):\n",
    "#             return 1+c\n",
    "#         else:\n",
    "#             self.b = -1.0 / c\n",
    "#             return rv_continuous._entropy(self, c)\n",
    "frechet = frechet_gen(a=0.0, name='frechet') # we specify the support [a,b], no b means b = infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_greatest_values_matrices(a,k):\n",
    "    \"\"\"returns k greatest elements from the list a and k - 1 value starting from which we consider greater values as extremes\"\"\"\n",
    "    # we prepare the matrix for the excesses, the last value of 1 could be substituted by any value within the range\n",
    "    mat = np.zeros( len(a[-1 - k + 1 : , 1] ) ) \n",
    "    # we prepare the vector in which we will return u values for each dataset in column of a\n",
    "    u = np.zeros(len(r[0 , : ] )) \n",
    "    for i in range(len(a[0,:])): \n",
    "        # index i goes through the columns, instead of len(a[0,:]) there could be len(a[i,:]) for i in range of columns\n",
    "        u[i] = a[-1 - k, i] \n",
    "        # u is a list of values s.t. bigger values are considered as excesses, for each set of data, i.e. for each column we save an u value\n",
    "        mat = np.column_stack( (mat,a[ -1 - k + 1 : , i]) ) \n",
    "    # in mat matrix we return the values of excesses but not yet transformed (y_i = x_i - u)\n",
    "    return(mat, u) # u is the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of sampled dataset over which we average the quantiles\n",
    "N, beta = 1000,  1/2\n",
    "k = 50\n",
    "\n",
    "r = frechet.rvs(beta, size=N)\n",
    "for i in range(n):\n",
    "    r = np.column_stack( (r, frechet.rvs(beta, size=N) ) ) \n",
    "\n",
    "# r = np.delete(r, 0, 1)    # delete first column with sampled data to much the sizes\n",
    "\n",
    "# we need to sort in increasing order gathered data\n",
    "for i in range(len(r[0,:])):\n",
    "    r[:,i] = np.sort(r[:,i], axis=None)# we sort data sampled from frechet, each dataset is in separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frechet,u = k_greatest_values_matrices(r,k) \n",
    "\n",
    "# delete first column (indexed by 0) of a matrix A, to match the sizes \n",
    "A = np.delete(data_frechet, 0, 1)\n",
    "\n",
    "# form the array of u values we create matrix, in columns we have repeated u values   \n",
    "B = [ [x] * k for x in u ] \n",
    "\n",
    "# here we subtract u_i from excesses in each dataset\n",
    "C = np.array(A) - np.array(B).transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y, real alpha, real beta) {\n",
    "      return -(alpha + 1)*( log(1+y/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  \n",
    "  real myBetaPrior_lpdf(real x, real beta) {\n",
    "      return -log(beta); // log(1/beta) = log(1) - log(beta) = - log(beta)\n",
    "  }\n",
    "  \n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors; no priors - we assume improper priors on params\n",
    "  alpha ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher = \"\"\"\n",
    "functions { \n",
    " real myFisher_lpdf(real y, real alpha1, real alpha2, real beta) {\n",
    "      return -lbeta(alpha1,alpha2)-log(beta)+(alpha1-1)*log(y/beta)-(alpha1+alpha2)*log(1+y/beta);\n",
    "  }\n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y[N]; \n",
    "}\n",
    "parameters { \n",
    "  //parameters of the Fisher\n",
    "  real<lower=0> alpha1;\n",
    "  real<lower=0> alpha2;\n",
    "  real<lower=0> beta; \n",
    "}\n",
    "model {\n",
    "  // when we deliberately do not specify priors then Stan works with improper priors\n",
    "  alpha1 ~ gamma(1,1);\n",
    "  alpha2 ~ gamma(1,1);\n",
    "  beta ~ gamma(1,1);\n",
    "   // Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myFisher_lpdf( y[n] |alpha1, alpha2, beta);\n",
    "  }\n",
    "}\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_ecbac65cce1d714e75f45a634ba1d39a NOW.\n",
      "C:\\Users\\Michal Lewandowski\\Anaconda3\\envs\\py35\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    }
   ],
   "source": [
    "data = dict(N = len(C[:,1]),  y = C[:,1]) \n",
    "fit = StanModel(model_code=Fisher).sampling(data=data,iter=1000,warmup=200, chains=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_ecbac65cce1d714e75f45a634ba1d39a.\n",
      "1 chains, each with iter=1000; warmup=200; thin=1; \n",
      "post-warmup draws per chain=800, total post-warmup draws=800.\n",
      "\n",
      "         mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "alpha1   1.39    0.02   0.37   0.78   1.15   1.34   1.57   2.34    331    1.0\n",
      "alpha2   1.37    0.02   0.33   0.81   1.14   1.34   1.56   2.13    179   1.01\n",
      "beta     1.65    0.07   0.84   0.54   1.02   1.52   2.09    3.6    166    1.0\n",
      "lp__   -113.5    0.09   1.31 -117.2 -114.1 -113.2 -112.6 -112.1    193    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Thu May 31 14:24:40 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
