{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simulate data from 3 distributions, we will be interested in excesses: k statistics for k \\in 50, 100, 150, ..., \n",
    "# to each excess we then fit GPD and Fisher distributions, with priors as already written \n",
    "\n",
    "# 1) we need to sample from exactly specified distributions: a) either create a class and sample rv from it or\n",
    "#                                                            b) use the transformation proposed by Julyan (easier)\n",
    "# 2) make replications of data sets, for each of the set obtain excesses, for each excess obtain the parameters\n",
    "# 3) try changing values of k, keep fitting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genereting random numbers from Frechet & Burr & log-gamma \n",
    "import pystan\n",
    "import numpy as np\n",
    "from pystan import StanModel \n",
    "from scipy.stats import frechet_r, loggamma, burr, invweibull\n",
    "# from scipy.stats import burr\n",
    "# from scipy.stats import loggamma\n",
    "N = 5000\n",
    "c = 1\n",
    "# frechet_r.pdf(x, c) =c*x**(-c-1)*exp(-x**-c)\n",
    "frechet = invweibull.rvs(c, size=N) # this is exactly the same as in publication, there beta = 1/c \n",
    "\n",
    "# burr distribution, burr(1, 1/2, 2)\n",
    "# burr_r.pdf = c * d * x**(-c-1) * ( 1 + x**( -c ) )**(- d - 1)\n",
    "c, d = 1, 0.5\n",
    "burr = burr.rvs(c, d, size=N)\n",
    "\n",
    "# log-gamma\n",
    "# probability density for loggamma: loggamma.pdf(x, c) = exp(c*x-exp(x)) / gamma(c)\n",
    "c = 2\n",
    "loggamma = loggamma.rvs(c, size=N)\n",
    "\n",
    "# i assume the pdfs are correct, now we need to save the k- greatest values from each distribution,\n",
    "# save the k-th greatest value u, \n",
    "# get the array of x_i - u and to those data fit both GPD and Fisher distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get k-greatest value from which we subtract the border value\n",
    "# a - list, k - we get k greatest values, \n",
    "\n",
    "def k_greatest_values(a,k):\n",
    "    \"\"\"returns k greatest elements from the list and k-1 value starting from which we consider values to be extreme\"\"\"\n",
    "    u = np.sort(a, axis=None)[-1-k]\n",
    "    a = np.sort(a, axis=None)[-1-k+1:]\n",
    "    a = [a-u for x in a]\n",
    "    return(a[1].tolist(), u) # u the starting value from which we consider others as excesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for instance we save k = 100 greatest values generated form frechet distribution\n",
    "k = 100\n",
    "data_frechet,u = k_greatest_values(frechet,k)\n",
    "data_frechet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPD = \"\"\"\n",
    "functions {\n",
    "  real myGPD_lpdf(real y2, real alpha, real beta) {\n",
    "      //return -(1+1/c)*log(1+c*y2);\n",
    "      return -(alpha + 1)*( log(1+y2/beta) )+(log(alpha) - log(beta));\n",
    "  }\n",
    "  // above distribution is a special case of the distribution in the paper for alpha = beta = 1 / c\n",
    "  // c = 1/beta\n",
    "}\n",
    "data { \n",
    "  int N;\n",
    "  real y2[N]; // points sampled from gpd in python with some(known) parameters, by mcmc we recover true values of those params\n",
    "}\n",
    "parameters { \n",
    "  //real c; \n",
    "  real alpha;\n",
    "  real beta;\n",
    "}\n",
    "model {\n",
    "  // Priors\n",
    "\n",
    "  // c ~ uniform(0,1);\n",
    "\n",
    "// Likelihood\n",
    "  for(n in 1:N) {\n",
    "    target += myGPD_lpdf( y2[n] | alpha, beta );\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "generated quantities{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpd\n",
    "# genpareto.pdf(x, c) = (1 + c * x)**(-1 - 1/c)\n",
    "from scipy.stats import genpareto\n",
    "c, N, beta  = 1, 100, 1\n",
    "r = genpareto.rvs(c, size=N)*beta*c\n",
    "r = r.tolist()\n",
    "np.sort(r)\n",
    "# [x - 5 for x in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(N = N,  y2 = r) # we provide data for our model, y is primarly an array, it needs to be converted to a list\n",
    "sm = StanModel(model_code=GPD) # we put the created model to the stan \n",
    "fit = sm.sampling(data=data,iter=1000, warmup=200, chains=1)# we sample from the provided data ;\n",
    "print(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving values of parameters of the fit\n",
    "beta = np.mean(list(fit.extract().values())[0].tolist())\n",
    "alpha = np.mean(list(fit.extract().values())[1].tolist())\n",
    "# alpha2 = list(fit.extract().values())[2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogtram of excess data adequatly transformed \n",
    "myHist = plt.hist(data_frechet, 100, normed=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation of quantiles \n",
    "def quantile_GPD(N, k, p, beta, gamma, u):\n",
    "    return( u + beta*( ( N * p / k )**( -gamma ) - 1 ) ) # p = 0.05\n",
    "\n",
    "def quantile_Fisher(N, F_y):\n",
    "    return(u + F_y) # F_y is inversed survival function available for programmed .f distribution in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(data_frechet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
